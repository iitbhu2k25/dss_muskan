# app/services/gsr_service.py

import os
import re
import uuid
import json
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from io import BytesIO

import geopandas as gpd
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
import matplotlib.patches as mpatches

BASE_MEDIA = "media"   # same as Django MEDIA_ROOT

# -----------------------------------------------------------
# Helper functions
# -----------------------------------------------------------

def parse_to_list(value) -> List[str]:
    """Parses a string, list, or None into a list of strings"""
    if value is None:
        return []
    if isinstance(value, list):
        return [str(v).strip() for v in value if str(v).strip()]
    return [s.strip() for s in re.split(r"[,\|]+", str(value)) if s.strip()]

def safe_string_compare(val1, val2) -> bool:
    """Safely compare two values as strings"""
    if pd.isna(val1) or pd.isna(val2):
        return False
    return str(val1).strip().lower() == str(val2).strip().lower()

def load_trend_data(trend_csv_filename: str) -> Dict[str, str]:
    """
    Load trend data from CSV file and return a mapping of Village_ID to trend_status
    """
    trend_map = {}
    
    if not trend_csv_filename:
        return trend_map
    
    try:
        # Construct the full path to the trend CSV file in media/temp/
        csv_path = os.path.join(BASE_MEDIA, "temp", trend_csv_filename)
        
        if not os.path.exists(csv_path):
            print(f"âš ï¸ Trend CSV file not found: {csv_path}")
            return trend_map
        
        # Read the trend CSV file
        trend_df = pd.read_csv(csv_path)
        print(f"ðŸ“„ Loaded trend CSV with {len(trend_df)} records from: {csv_path}")
        
        # Create mapping from Village_ID to trend_status
        for _, row in trend_df.iterrows():
            village_id = str(row.get('Village_ID', '')).strip()
            trend_status = str(row.get('Trend_Status', 'Unknown')).strip()
            
            if village_id:
                trend_map[village_id] = trend_status
        
        print(f"ðŸŽ¯ Created trend mapping for {len(trend_map)} villages using Village_ID")
        
    except Exception as e:
        print(f"âŒ Error loading trend data: {str(e)}")
    
    return trend_map

def load_village_shapefile() -> Optional[gpd.GeoDataFrame]:
    """
    Load village shapefile from the specified path
    """
    try:
        shapefile_path = os.path.join(
            BASE_MEDIA, 
            'gwa_data', 
            'gwa_shp', 
            'Final_Village', 
            'Village.shp'
        )
        
        if not os.path.exists(shapefile_path):
            print(f"âš ï¸ Village shapefile not found: {shapefile_path}")
            return None
        
        # Read the shapefile
        village_gdf = gpd.read_file(shapefile_path)
        print(f"ðŸ—ºï¸ Loaded village shapefile with {len(village_gdf)} villages from: {shapefile_path}")
        print(f"ðŸ“‹ Shapefile columns: {list(village_gdf.columns)}")
        
        # Ensure village_co column exists and is string type
        if 'village_co' in village_gdf.columns:
            village_gdf['village_co'] = village_gdf['village_co'].astype(str).str.strip()
            print(f"âœ… Found village_co column with {len(village_gdf['village_co'].unique())} unique values")
        else:
            print("âŒ village_co column not found in shapefile")
            return None
        
        return village_gdf
        
    except Exception as e:
        print(f"âŒ Error loading village shapefile: {str(e)}")
        return None

def merge_gsr_with_shapefile(gsr_results: List[Dict[str, Any]], village_gdf: gpd.GeoDataFrame) -> Dict[str, Any]:
    """
    Merge GSR results with village shapefile and return GeoJSON
    Only includes villages that have GSR data (inner join)
    """
    try:
        # Convert GSR results to DataFrame for easier merging
        gsr_df = pd.DataFrame(gsr_results)
        
        # Use inner join to only get villages that have GSR data
        merged_gdf = village_gdf.merge(
            gsr_df, 
            left_on='village_co', 
            right_on='village_code', 
            how='inner'  # Only keep matching villages
        )
        
        print(f"ðŸ”— Merged {len(merged_gdf)} villages with GSR data (inner join)")
        print(f"ðŸ“Š Original GSR data villages: {len(gsr_df)}")
        print(f"ðŸ“Š Shapefile villages: {len(village_gdf)}")
        print(f"ðŸ“Š Final merged villages: {len(merged_gdf)}")
        
        # Convert to GeoJSON
        # Handle any potential issues with geometry serialization
        merged_gdf = merged_gdf.to_crs('EPSG:4326')  # Ensure WGS84 for web compatibility
        
        # Convert to GeoJSON format
        geojson = merged_gdf.to_json()
        geojson_dict = json.loads(geojson)
        
        # Add metadata about the merge
        merge_stats = {
            'total_shapefile_villages': len(village_gdf),
            'total_gsr_villages': len(gsr_df),
            'villages_with_geospatial_data': len(merged_gdf),
            'villages_without_geospatial_data': len(gsr_df) - len(merged_gdf),
            'match_success_rate': round(len(merged_gdf) / len(gsr_df) * 100, 2) if len(gsr_df) > 0 else 0
        }
        
        return {
            'geojson': geojson_dict,
            'merge_statistics': merge_stats,
            'merged_gdf': merged_gdf  # Return the GeoDataFrame for map plotting
        }
        
    except Exception as e:
        print(f"âŒ Error merging GSR data with shapefile: {str(e)}")
        return {
            'geojson': None,
            'merge_statistics': {
                'error': str(e),
                'total_shapefile_villages': len(village_gdf) if village_gdf is not None else 0,
                'total_gsr_villages': len(gsr_results),
                'villages_with_geospatial_data': 0,
                'villages_without_geospatial_data': len(gsr_results),
                'match_success_rate': 0
            },
            'merged_gdf': None
        }

def generate_gsr_map_image(merged_gdf: gpd.GeoDataFrame) -> Optional[str]:
    """
    Generate GSR classification map with performance optimizations.
    """
    try:
        import contextlib
        with contextlib.suppress(ImportError):
            import contextily as ctx
            
        if merged_gdf is None or len(merged_gdf) == 0:
            print("âš ï¸ No merged GeoDataFrame available for map generation")
            return None

        # 1. Simplify geometries for faster rendering
        merged_gdf_simplified = merged_gdf.copy()
        merged_gdf_simplified['geometry'] = merged_gdf_simplified['geometry'].simplify(
            tolerance=0.0001,
            preserve_topology=True
        )

        # 2. Keep in EPSG:4326 (lat/long degrees)
        merged_gdf_web = merged_gdf_simplified.to_crs(epsg=4326)

        # 3. Create figure
        fig, ax = plt.subplots(1, 1, figsize=(15, 12))

        # 4. Get unique classifications
        classification_labels = merged_gdf_web['gsr_classification'].unique()
        classification_labels = [cl for cl in classification_labels if cl]

        # 5. Vectorized color mapping
        colors = merged_gdf_web['gsr_classification'].map(get_classification_color).fillna('gray')

        # 6. Plot with same style as original
        merged_gdf_web.plot(
            ax=ax,
            color=colors,
            edgecolor='black',
            linewidth=0.75,
            alpha=1,
            rasterized=True  # Added for performance
        )

        # 7. Add OpenStreetMap basemap if contextily is available
        try:
            if 'ctx' in locals():
                ctx.add_basemap(
                    ax,
                    crs=merged_gdf_web.crs,  # Use EPSG:4326
                    source=ctx.providers.CartoDB.Voyager,  # CartoDB Voyager basemap
                    alpha=1,
                    zoom=10
                )
        except Exception as e:
            print(f"âš ï¸ Basemap loading failed: {e}")

        # 8. Title and labels
        ax.set_title('GSR Classification Map\n(Groundwater Supply-Requirement Analysis)',
                     fontsize=16, fontweight='bold', pad=20)
        ax.set_xlabel('LONGITUDE', fontsize=12)
        ax.set_ylabel('LATITUDE', fontsize=12)

        # 9. Create legend
        classification_counts = merged_gdf_web['gsr_classification'].value_counts()
        
        legend_handles = []
        for cl in classification_labels:
            color = get_classification_color(cl)
            count = classification_counts.get(cl, 0)
            patch = mpatches.Patch(color=color, label=f"{cl} ({count})")
            legend_handles.append(patch)

        ax.legend(
            handles=legend_handles,
            title='GSR Classifications',
            title_fontsize=12,
            fontsize=10,
            loc='upper left',
            bbox_to_anchor=(1.02, 1),
            frameon=True,
            fancybox=True,
            shadow=True
        )

        ax.tick_params(axis='both', which='major', labelsize=10)
        ax.grid(True, alpha=0.3)
        plt.tight_layout()

        # 10. Generate filename
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        unique_id = str(uuid.uuid4())[:8]
        filename = f"gsr_map_{timestamp}_{unique_id}.png"
        temp_dir = os.path.join(BASE_MEDIA, 'temp')
        os.makedirs(temp_dir, exist_ok=True)
        filepath = os.path.join(temp_dir, filename)

        # 11. Save with reduced DPI
        buffer = BytesIO()
        
        plt.savefig(
            buffer,
            format='png',
            dpi=150,
            bbox_inches='tight',
            facecolor='white',
            edgecolor='none'
        )
        
        # Write buffer to file
        buffer.seek(0)
        with open(filepath, 'wb') as f:
            f.write(buffer.read())
        
        buffer.close()
        plt.close(fig)

        print(f"ðŸ—ºï¸ GSR map image saved successfully: {filepath}")
        print(f"ðŸ“Š Map contains {len(merged_gdf)} villages with GSR data")
        return filename

    except Exception as e:
        print(f"âŒ Error generating GSR map image: {str(e)}")
        plt.close('all')
        return None

def calculate_gsr_classification(gsr_value: float, trend_status: str) -> str:
    """
    Calculate GSR classification based on GSR ratio and trend status
    According to the classification table provided
    """
    if gsr_value is None:
        return "No Data"
    
    # Handle "No Trend Data" case - treat as "No Trend"
    if trend_status == "No Trend Data":
        trend_status = "No Trend"
    
    # Normalize trend status
    trend_status = trend_status.strip().lower()
    
    # Classification logic based on the table
    if trend_status == "increasing":
        if gsr_value < 0.95:
            return "Critical"
        elif 0.95 <= gsr_value <= 1.05:
            return "Safe"
        else:  # gsr_value > 1.05
            return "Very Safe"
    
    elif trend_status == "decreasing":
        if gsr_value < 0.95:
            return "Over Exploited"
        elif 0.95 <= gsr_value <= 1.05:
            return "Critical"
        else:  # gsr_value > 1.05
            return "Very Semi-Critical"
    
    # Handle "No Trend" cases (including any other trend status)
    else:  # This covers "no trend", "stable", and any other trend status
        if gsr_value < 0.95:
            return "Over Exploited"
        elif 0.95 <= gsr_value <= 1.05:
            return "Safe"
        else:  # gsr_value > 1.05
            return "Very Safe"

def get_classification_color(classification: str) -> str:
    """
    Return CSS color name for each of the 6 classifications
    """
    color_map = {
        'Critical': 'red',
        'Safe': 'green',
        'Very Safe': 'teal',
        'Over Exploited': 'darkred',
        'Very Semi-Critical': 'orange',
        'No Data': 'transparent',
    }
    return color_map.get(classification, 'gray')

def match_village_data(
    recharge_data: List[Dict[str, Any]],
    domestic_data: List[Dict[str, Any]], 
    agricultural_data: List[Dict[str, Any]],
    industrial_data: List[Dict[str, Any]],
    trend_csv_filename: Optional[str] = None
) -> List[Dict[str, Any]]:
    """
    Match village data across recharge, domestic, agricultural, industrial datasets, and trend data
    """
    # Load trend data if filename is provided
    trend_map = load_trend_data(trend_csv_filename) if trend_csv_filename else {}
    
    # Create mappings for each dataset
    recharge_map = {}
    domestic_map = {}
    agricultural_map = {}
    industrial_map = {}
    
    # Process recharge data - using village_co as key
    for item in recharge_data:
        village_code = str(item.get('village_co', '')).strip()
        if village_code:
            recharge_map[village_code] = {
                'recharge': float(item.get('recharge', 0) or 0),
                'raw_data': item
            }
    
    # Process domestic data - using village_code as key
    for item in domestic_data:
        village_code = str(item.get('village_code', '')).strip()
        if village_code:
            domestic_map[village_code] = {
                'domestic_demand': float(item.get('demand_mld', 0) or 0),
                'raw_data': item
            }
    
    # Process agricultural data - using village_code as key
    for item in agricultural_data:
        village_code = str(item.get('village_code', '')).strip()
        if village_code:
            agricultural_map[village_code] = {
                'agricultural_demand': float(item.get('village_demand', 0) or 0),
                'raw_data': item
            }
    
    # Process industrial data - using village_code as key
    for item in industrial_data:
        village_code = str(item.get('village_code', '')).strip()
        if village_code:
            industrial_map[village_code] = {
                'industrial_demand': float(item.get('demand_mld', 0) or 0),
                'raw_data': item
            }
    
    # Get all unique village codes
    all_village_codes = set(recharge_map.keys()) | set(domestic_map.keys()) | set(agricultural_map.keys()) | set(industrial_map.keys())
    
    results = []
    
    for village_code in all_village_codes:
        # Get data for this village
        recharge_info = recharge_map.get(village_code, {})
        domestic_info = domestic_map.get(village_code, {})
        agricultural_info = agricultural_map.get(village_code, {})
        industrial_info = industrial_map.get(village_code, {})
        
        recharge = recharge_info.get('recharge', 0)
        domestic_demand = domestic_info.get('domestic_demand', 0)
        agricultural_demand = agricultural_info.get('agricultural_demand', 0)
        industrial_demand = industrial_info.get('industrial_demand', 0)
        
        # Calculate total demand (including industrial)
        total_demand = domestic_demand + agricultural_demand + industrial_demand
        
        # Calculate GSR (avoiding division by zero)
        if total_demand > 0:
            gsr = recharge / total_demand
            gsr_status = "Sustainable" if gsr >= 1.0 else "Stressed"
        else:
            gsr = None
            gsr_status = "No Demand"
        
        # Get trend status for this village using Village_ID from trend CSV
        trend_status = trend_map.get(village_code, "No Trend Data")
        
        # Calculate GSR classification based on GSR value and trend
        gsr_classification = calculate_gsr_classification(gsr, trend_status)
        
        # Get color for the classification
        classification_color = get_classification_color(gsr_classification)
        
        # Get additional village information from raw data
        village_info = {
            'village_name': 'N/A',
            'subdistrict_code': 'N/A'
        }
        
        # Try to get village name and other info from any available dataset
        for raw_data in [recharge_info.get('raw_data', {}), 
                        domestic_info.get('raw_data', {}), 
                        agricultural_info.get('raw_data', {}),
                        industrial_info.get('raw_data', {})]:
            if raw_data:
                if village_info['village_name'] == 'N/A':
                    village_info['village_name'] = raw_data.get('village_name', 
                                                             raw_data.get('village', 'N/A'))
                if village_info['subdistrict_code'] == 'N/A':
                    village_info['subdistrict_code'] = raw_data.get('subdistrict_code', 
                                                                  raw_data.get('subdis_cod', 'N/A'))
        
        # Create result record with classification and color fields
        result = {
            'village_code': village_code,
            'village_name': village_info['village_name'],
            'subdistrict_code': village_info['subdistrict_code'],
            'recharge': round(recharge, 4),
            'domestic_demand': round(domestic_demand, 4),
            'agricultural_demand': round(agricultural_demand, 4),
            'industrial_demand': round(industrial_demand, 4),
            'total_demand': round(total_demand, 4),
            'gsr': round(gsr, 4) if gsr is not None else None,
            'gsr_status': gsr_status,
            'trend_status': trend_status,                  
            'gsr_classification': gsr_classification,       
            'classification_color': classification_color,    
            'has_recharge_data': village_code in recharge_map,
            'has_domestic_data': village_code in domestic_map,
            'has_agricultural_data': village_code in agricultural_map,
            'has_industrial_data': village_code in industrial_map,
            'has_trend_data': village_code in trend_map
        }
        
        results.append(result)
    
    return results

def calculate_gsr_summary(results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Calculate summary statistics for GSR analysis including classification distribution"""
    
    if not results:
        return {}
    
    total_villages = len(results)
    total_recharge = sum(r['recharge'] for r in results)
    total_domestic = sum(r['domestic_demand'] for r in results)
    total_agricultural = sum(r['agricultural_demand'] for r in results)
    total_industrial = sum(r['industrial_demand'] for r in results)
    total_demand = sum(r['total_demand'] for r in results)
    
    # Count villages by status
    sustainable_count = sum(1 for r in results if r['gsr_status'] == 'Sustainable')
    stressed_count = sum(1 for r in results if r['gsr_status'] == 'Stressed')
    no_demand_count = sum(1 for r in results if r['gsr_status'] == 'No Demand')
    
    # Count villages by trend status
    trend_counts = {}
    villages_with_trend_data = sum(1 for r in results if r['has_trend_data'])
    
    for result in results:
        trend_status = result['trend_status']
        trend_counts[trend_status] = trend_counts.get(trend_status, 0) + 1
    
    # Count villages by classification
    classification_counts = {}
    for result in results:
        classification = result['gsr_classification']
        classification_counts[classification] = classification_counts.get(classification, 0) + 1
    
    # Calculate overall GSR
    overall_gsr = total_recharge / total_demand if total_demand > 0 else None
    
    # Calculate average GSR (excluding villages with no demand)
    valid_gsr_values = [r['gsr'] for r in results if r['gsr'] is not None]
    avg_gsr = sum(valid_gsr_values) / len(valid_gsr_values) if valid_gsr_values else 0
    
    return {
        'total_villages': total_villages,
        'total_recharge': round(total_recharge, 4),
        'total_domestic_demand': round(total_domestic, 4),
        'total_agricultural_demand': round(total_agricultural, 4),
        'total_industrial_demand': round(total_industrial, 4),
        'total_demand': round(total_demand, 4),
        'overall_gsr': round(overall_gsr, 4) if overall_gsr is not None else None,
        'average_gsr': round(avg_gsr, 4),
        'sustainable_villages': sustainable_count,
        'stressed_villages': stressed_count,
        'no_demand_villages': no_demand_count,
        'sustainability_percentage': round((sustainable_count / total_villages) * 100, 2) if total_villages > 0 else 0,
        'villages_with_trend_data': villages_with_trend_data,
        'trend_distribution': trend_counts,
        'classification_distribution': classification_counts  
    }
